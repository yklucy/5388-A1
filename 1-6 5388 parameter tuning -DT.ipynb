{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a62848c",
   "metadata": {},
   "source": [
    "# Read train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89609d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import ExtraTreesClassifier, IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel, VarianceThreshold\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998dc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ read data sets from files ^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-03\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "\n",
    "#read data sets from files\n",
    "data = pd.read_csv(r\"./traindata.csv\")\n",
    "testdata = pd.read_csv(r\"./testdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfebf867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2acc443",
   "metadata": {},
   "source": [
    "# parameters tuning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d01161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "score_sf_re: \n",
      "      fit_time  score_time  test_recall   test_f1  test_accuracy  test_roc_auc  \\\n",
      "avg  0.456422    0.050535     0.996546  0.995731       0.995913      0.995940   \n",
      "std  0.127955    0.014549     0.001136  0.000957       0.000916      0.000917   \n",
      "\n",
      "     test_precision  \n",
      "avg        0.994919  \n",
      "std        0.001159  \n"
     ]
    }
   ],
   "source": [
    "# -------------- train predictive model with pipeline: MinMaxScaler(), VarianceThreshold(), cross_validate()--------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mm = MinMaxScaler()\n",
    "#mm = StandardScaler()\n",
    "\n",
    "selector = VarianceThreshold(np.median(data_aftcat.var().values))\n",
    "model = DecisionTreeClassifier(random_state=10, criterion='gini', max_depth=18, max_features=25, min_impurity_decrease=0.0, min_samples_leaf=1, splitter='best')\n",
    "    \n",
    "#model = RandomForestClassifier(random_state = 90, min_samples_split=2,n_estimators=61,max_depth=24, max_features=27,min_samples_leaf=1, n_jobs=-1)\n",
    "#model = GradientBoostingClassifier(max_features=3,learning_rate=0.1,n_estimators=130,min_samples_split=100,min_samples_leaf=7,max_depth=15,random_state = 10)\n",
    "#model = MLPClassifier(random_state=1, max_iter=10000,hidden_layer_sizes = (160,160), activation='tanh',solver='adam')\n",
    "\n",
    "print(\"DT\")\n",
    "\n",
    "pipe_steps = [('mm',mm),('selector',selector),('model',model)]\n",
    "id_pipeline = Pipeline(steps=pipe_steps)\n",
    "\n",
    "# evaluate the pipeline using the crossvalidation technique defined in cv\n",
    "\n",
    "# ------------------- score ------------------------------------\n",
    "def score_mean_std(score_sf):\n",
    "    index_a1 = []\n",
    "    index_a2 = []\n",
    "\n",
    "    for i in range(score_sf.shape[1]):\n",
    "        index_a1.append(np.average(score_sf[score_sf.columns[i]]))\n",
    "        index_a2.append(np.std(score_sf[score_sf.columns[i]]))\n",
    "\n",
    "    index_a1 = pd.DataFrame(index_a1, index = score_sf.columns)\n",
    "    index_a2 = pd.DataFrame(index_a2, index = score_sf.columns)\n",
    "    #print(index_a1.T)\n",
    "    #print(index_a2.T)\n",
    "    re = pd.concat([index_a1.T,index_a2.T],axis=0)\n",
    "    re.index = [\"avg\",\"std\"]\n",
    "    #print(re)\n",
    "    return re\n",
    "\n",
    "\n",
    "scoring = {'f1', 'precision', 'accuracy',\n",
    "           'recall', 'roc_auc'}\n",
    "score_sf = cross_validate(id_pipeline, data_aftcat, data_y.values.ravel(),cv=10,scoring=scoring, n_jobs=-1)\n",
    "score_sf_re = score_mean_std(pd.DataFrame(score_sf))\n",
    "\n",
    "print(\"score_sf_re: \\n\", pd.DataFrame(score_sf_re))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1eb7d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 10216\n"
     ]
    }
   ],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Prediction  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# step 1: use train data MinMaxScaler() fit to transform test data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "tmm = MinMaxScaler().fit(data_aftcat)\n",
    "result_train = tmm.transform(data_aftcat)\n",
    "X_train = pd.DataFrame(result_train)\n",
    "X_train.columns = tmm.get_feature_names_out()\n",
    "#print(\"X_train\",X_train.info())\n",
    "\n",
    "\n",
    "result_test = tmm.transform(testdata_aftcat)\n",
    "X_test = pd.DataFrame(result_test)\n",
    "X_test.columns = tmm.get_feature_names_out()\n",
    "#print(\"X_test\",X_test.info())\n",
    "\n",
    "# step 2: use train data VarianceThreshold() fit to transform test data\n",
    "ss = selector.fit(data_aftcat)\n",
    "newdata = pd.DataFrame(ss.transform(X_train))\n",
    "newdata.columns = ss.get_feature_names_out()  \n",
    "#print(\"newddata:\",newdata.head())\n",
    "                       \n",
    "newtestdata = pd.DataFrame(ss.transform(X_test))\n",
    "newtestdata.columns = ss.get_feature_names_out()\n",
    "#print(\"newtestdata:\",newtestdata.head())\n",
    "\n",
    "# step 3: prediction\n",
    "model.fit(newdata,data_y.values.ravel())\n",
    "\n",
    "y_pre = model.predict(newtestdata).astype(int)\n",
    "print(\"sum:\",y_pre.sum())\n",
    "\n",
    "pre = pd.DataFrame(columns=[\"ID\",\"Class\"])\n",
    "pre[\"ID\"] = range(y_pre.shape[0])\n",
    "pre[\"Class\"] = y_pre\n",
    "pre.to_csv(r'./DT-pre.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fcef1",
   "metadata": {},
   "source": [
    "# round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "376a2e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "score_sf_re: \n",
      "      fit_time  score_time  test_recall   test_f1  test_accuracy  test_roc_auc  \\\n",
      "avg  0.368750    0.052989      0.99600  0.995277       0.995479      0.996239   \n",
      "std  0.065035    0.018917      0.00142  0.001269       0.001217      0.001463   \n",
      "\n",
      "     test_precision  \n",
      "avg        0.994559  \n",
      "std        0.002171  \n"
     ]
    }
   ],
   "source": [
    "# -------------- train predictive model with pipeline: MinMaxScaler(), VarianceThreshold(), cross_validate()--------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mm = MinMaxScaler()\n",
    "#mm = StandardScaler()\n",
    "\n",
    "selector = VarianceThreshold(np.median(data_aftcat.var().values))\n",
    "model = DecisionTreeClassifier(random_state=10, criterion='gini', max_depth=12, max_features=25, min_impurity_decrease=0.0, min_samples_leaf=1, splitter='best')\n",
    "print(\"DT\")\n",
    "\n",
    "pipe_steps = [('mm',mm),('selector',selector),('model',model)]\n",
    "id_pipeline = Pipeline(steps=pipe_steps)\n",
    "\n",
    "# evaluate the pipeline using the crossvalidation technique defined in cv\n",
    "\n",
    "# ------------------- score ------------------------------------\n",
    "def score_mean_std(score_sf):\n",
    "    index_a1 = []\n",
    "    index_a2 = []\n",
    "\n",
    "    for i in range(score_sf.shape[1]):\n",
    "        index_a1.append(np.average(score_sf[score_sf.columns[i]]))\n",
    "        index_a2.append(np.std(score_sf[score_sf.columns[i]]))\n",
    "\n",
    "    index_a1 = pd.DataFrame(index_a1, index = score_sf.columns)\n",
    "    index_a2 = pd.DataFrame(index_a2, index = score_sf.columns)\n",
    "    #print(index_a1.T)\n",
    "    #print(index_a2.T)\n",
    "    re = pd.concat([index_a1.T,index_a2.T],axis=0)\n",
    "    re.index = [\"avg\",\"std\"]\n",
    "    #print(re)\n",
    "    return re\n",
    "\n",
    "\n",
    "scoring = {'f1', 'precision', 'accuracy',\n",
    "           'recall', 'roc_auc'}\n",
    "score_sf = cross_validate(id_pipeline, data_aftcat, data_y.values.ravel(),cv=10,scoring=scoring, n_jobs=-1)\n",
    "score_sf_re = score_mean_std(pd.DataFrame(score_sf))\n",
    "\n",
    "print(\"score_sf_re: \\n\", pd.DataFrame(score_sf_re))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aab69890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 10289\n"
     ]
    }
   ],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Prediction  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# step 1: use train data MinMaxScaler() fit to transform test data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "tmm = MinMaxScaler().fit(data_aftcat)\n",
    "result_train = tmm.transform(data_aftcat)\n",
    "X_train = pd.DataFrame(result_train)\n",
    "X_train.columns = tmm.get_feature_names_out()\n",
    "#print(\"X_train\",X_train.info())\n",
    "\n",
    "\n",
    "result_test = tmm.transform(testdata_aftcat)\n",
    "X_test = pd.DataFrame(result_test)\n",
    "X_test.columns = tmm.get_feature_names_out()\n",
    "#print(\"X_test\",X_test.info())\n",
    "\n",
    "# step 2: use train data VarianceThreshold() fit to transform test data\n",
    "ss = selector.fit(data_aftcat)\n",
    "newdata = pd.DataFrame(ss.transform(X_train))\n",
    "newdata.columns = ss.get_feature_names_out()  \n",
    "#print(\"newddata:\",newdata.head())\n",
    "                       \n",
    "newtestdata = pd.DataFrame(ss.transform(X_test))\n",
    "newtestdata.columns = ss.get_feature_names_out()\n",
    "#print(\"newtestdata:\",newtestdata.head())\n",
    "\n",
    "# step 3: prediction\n",
    "model.fit(newdata,data_y.values.ravel())\n",
    "\n",
    "y_pre = model.predict(newtestdata).astype(int)\n",
    "print(\"sum:\",y_pre.sum())\n",
    "\n",
    "pre = pd.DataFrame(columns=[\"ID\",\"Class\"])\n",
    "pre[\"ID\"] = range(y_pre.shape[0])\n",
    "pre[\"Class\"] = y_pre\n",
    "pre.to_csv(r'./DT-pre.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc7875",
   "metadata": {},
   "source": [
    "# Round 1 - DT   max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1bc6b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9959105326468153 18\n"
     ]
    }
   ],
   "source": [
    "# -------------- train predictive model with pipeline: MinMaxScaler(), VarianceThreshold(), cross_validate()--------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mm = MinMaxScaler()\n",
    "#mm = StandardScaler()\n",
    "\n",
    "data_aftcat_mm = MinMaxScaler().fit_transform(data_aftcat, data_y.values.ravel())\n",
    "\n",
    "selector = VarianceThreshold(np.median(data_aftcat.var().values))\n",
    "#model = DecisionTreeClassifier(random_state=10, criterion='gini', max_depth=12, max_features=25, min_impurity_decrease=0.0, min_samples_leaf=1, splitter='best')\n",
    "#model = DecisionTreeClassifier(random_state=10)\n",
    "\n",
    "\n",
    "\n",
    "te = []\n",
    "for i in range(20):\n",
    "    model = DecisionTreeClassifier(random_state=25,max_depth=i+1) \n",
    "    pipe_steps = [('mm',mm),('selector',selector),('model',model)]\n",
    "    id_pipeline = Pipeline(steps=pipe_steps)\n",
    "    \n",
    "    score_sf = cross_validate(id_pipeline, data_aftcat, data_y.values.ravel(),cv=10,scoring='f1', n_jobs=-1)\n",
    "    #print(\"score_sf:\", score_sf['test_score'])\n",
    "    score_te = np.average(pd.DataFrame(score_sf['test_score']))\n",
    "    te.append(score_te)\n",
    "\n",
    "print(max(te),te.index(max(te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 2 - DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cb68cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975893951031413\n",
      "{'criterion': 'gini', 'max_depth': 14, 'max_features': 37, 'min_samples_leaf': 1, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# -------------- train predictive model with pipeline: MinMaxScaler(), VarianceThreshold(), cross_validate()--------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "#mm = StandardScaler()\n",
    "\n",
    "selector = VarianceThreshold(np.median(data_aftcat.var().values))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'splitter':('best','random')\n",
    "             ,'criterion':(\"gini\",\"entropy\")\n",
    "             ,\"max_depth\":[*range(2,20)]\n",
    "             ,'min_samples_leaf':[*range(1,4,3)]\n",
    "             ,'max_features':[*range(1,40,1)]\n",
    "             }\n",
    "model = DecisionTreeClassifier(random_state=25) \n",
    "pipe_steps = [('mm',mm),('selector',selector),('model',model)]\n",
    "id_pipeline = Pipeline(steps=pipe_steps)\n",
    "#score_sf = cross_validate(id_pipeline, data_aftcat, data_y.values.ravel(),cv=10,scoring='f1', n_jobs=-1)\n",
    "\n",
    "GS = GridSearchCV(model, parameters, cv=10, scoring='f1')\n",
    "GS.fit(data_aftcat, data_y.values.ravel())\n",
    "print(GS.best_score_)\n",
    "print(GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be061c9",
   "metadata": {},
   "source": [
    "###### model = DecisionTreeClassifier(random_state=25, criterion='gini', max_depth = 14, max_features=37, min_samples_leaf=1, splitter='best') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e47684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 3 - DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- train predictive model with pipeline: MinMaxScaler(), VarianceThreshold(), cross_validate()--------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "#mm = StandardScaler()\n",
    "\n",
    "selector = VarianceThreshold(np.median(data_aftcat.var().values))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'splitter':('best','random')\n",
    "             ,'criterion':(\"gini\",\"entropy\")\n",
    "             ,\"max_depth\":[*range(2,20)]\n",
    "             ,'min_samples_leaf':[*range(1,4,3)]\n",
    "             ,'max_features':[*range(1,40,1)]\n",
    "             }\n",
    "model = DecisionTreeClassifier(random_state=25, criterion='gini', max_depth = 14, max_features=37, min_samples_leaf=1, splitter='best') \n",
    "pipe_steps = [('mm',mm),('selector',selector),('model',model)]\n",
    "id_pipeline = Pipeline(steps=pipe_steps)\n",
    "#score_sf = cross_validate(id_pipeline, data_aftcat, data_y.values.ravel(),cv=10,scoring='f1', n_jobs=-1)\n",
    "\n",
    "GS = GridSearchCV(model, parameters, cv=10, scoring='f1')\n",
    "GS.fit(data_aftcat, data_y.values.ravel())\n",
    "print(GS.best_score_)\n",
    "print(GS.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
