{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51bc972",
   "metadata": {},
   "source": [
    "# Compare four algorithms (RF, GRB, MLP, DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31890b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f9b3314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from dataset (after categorical feature preprocessing and anomaly detection(IF))\n",
    "# not the dataset after MinMaxScaler\n",
    "data_aftcat_aftif = pd.read_csv(r\"./1-4 5388 traindata_aftcat_aftif.csv\")\n",
    "data_aftcat_aftif_y = pd.read_csv(r\"./1-4 5388 traindata_aftcat_aftif_label.csv\")\n",
    "\n",
    "testdata_aftcat = pd.read_csv(r\"./1-1 5388 testdata_aftcat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ab4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average f1 and std\n",
    "def score_mean_std(score_sf):\n",
    "    index_a1 = []\n",
    "    index_a2 = []\n",
    "\n",
    "    for i in range(score_sf.shape[1]):\n",
    "        index_a1.append(np.average(score_sf[score_sf.columns[i]]))\n",
    "        index_a2.append(np.std(score_sf[score_sf.columns[i]]))\n",
    "\n",
    "    index_a1 = pd.DataFrame(index_a1, index = score_sf.columns)\n",
    "    index_a2 = pd.DataFrame(index_a2, index = score_sf.columns)\n",
    "    #print(index_a1.T)\n",
    "    #print(index_a2.T)\n",
    "    re = pd.concat([index_a1.T,index_a2.T],axis=0)\n",
    "    re.index = [\"avg\",\"std\"]\n",
    "    #print(re)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5e8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^ train models: RF, GRB, MLP, DT ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-03\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "selector = VarianceThreshold(np.median(data_aftcat_aftif.var().values))\n",
    "model_rf = RandomForestClassifier(random_state = 90, min_samples_split=2,n_estimators=61,max_depth=24, max_features=27,min_samples_leaf=1, n_jobs=-1)\n",
    "model_grb = GradientBoostingClassifier(max_features=3,learning_rate=0.1,n_estimators=130,min_samples_split=100,min_samples_leaf=7,max_depth=15,random_state = 10)\n",
    "model_mlp = MLPClassifier(random_state=1, max_iter=10000,hidden_layer_sizes = (160,160), activation='tanh',solver='adam')\n",
    "model_dt = DecisionTreeClassifier(random_state=10, criterion='gini', max_depth=18, max_features=25, min_impurity_decrease=0.0, min_samples_leaf=1, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a49f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- train predictive model with pipeline: MinMaxScaler(), VarianceThreshold(), cross_validate()--------\n",
    "# return score\n",
    "def train_model(m, se, model, X, y):\n",
    "    print(model, \"\\n\")\n",
    "    pipe_steps = [('mm',m),('selector',se),('model',model)]\n",
    "    id_pipeline = Pipeline(steps=pipe_steps)\n",
    "\n",
    "    # evaluate the pipeline using the crossvalidation technique defined in cv\n",
    "\n",
    "    # ------------------- score ------------------------------------\n",
    "    scoring = {'f1', 'precision', 'accuracy',\n",
    "            'recall', 'roc_auc'}\n",
    "\n",
    "    score_sf = cross_validate(id_pipeline, X, y.values.ravel(),cv=10,scoring=scoring, n_jobs=-1)\n",
    "    score_sf_re = score_mean_std(pd.DataFrame(score_sf))\n",
    "\n",
    "    print(\"score_sf_re: \\n\", pd.DataFrame(score_sf_re))\n",
    "    return score_sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c257c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=24, max_features=27, n_estimators=61,\n",
      "                       n_jobs=-1, random_state=90) \n",
      "\n",
      "score_sf_re: \n",
      "      fit_time  score_time   test_f1  test_precision  test_recall  \\\n",
      "avg  4.389243    0.143868  0.997910        0.997459     0.998364   \n",
      "std  0.817042    0.034510  0.000866        0.001558     0.000793   \n",
      "\n",
      "     test_accuracy  test_roc_auc  \n",
      "avg       0.997999      0.999985  \n",
      "std       0.000830      0.000011  \n",
      "         RF\n",
      "0  0.998180\n",
      "1  0.997275\n",
      "2  0.996370\n",
      "3  0.999545\n",
      "4  0.997273\n",
      "5  0.997730\n",
      "6  0.999091\n",
      "7  0.997726\n",
      "8  0.998183\n",
      "9  0.997730\n"
     ]
    }
   ],
   "source": [
    "# -------------------- RF -----------------------\n",
    "score_sf_rf = train_model(mm, selector, model_rf, data_aftcat_aftif, data_aftcat_aftif_y)\n",
    "RF = pd.DataFrame(score_sf_rf['test_f1'],columns = [\"RF\"])\n",
    "print(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4fe66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_depth=15, max_features=3, min_samples_leaf=7,\n",
      "                           min_samples_split=100, n_estimators=130,\n",
      "                           random_state=10) \n",
      "\n",
      "score_sf_re: \n",
      "      fit_time  score_time   test_f1  test_precision  test_recall  \\\n",
      "avg  6.683303    0.116024  0.998137        0.997913     0.998364   \n",
      "std  1.261962    0.041753  0.000591        0.001342     0.001273   \n",
      "\n",
      "     test_accuracy  test_roc_auc  \n",
      "avg       0.998217      0.999986  \n",
      "std       0.000565      0.000018  \n",
      "        GRB\n",
      "0  0.997270\n",
      "1  0.997726\n",
      "2  0.997280\n",
      "3  0.999091\n",
      "4  0.998636\n",
      "5  0.998637\n",
      "6  0.998637\n",
      "7  0.997724\n",
      "8  0.998182\n",
      "9  0.998185\n"
     ]
    }
   ],
   "source": [
    "# -------------------- GRB -----------------------\n",
    "score_sf_grb = train_model(mm, selector, model_grb, data_aftcat_aftif, data_aftcat_aftif_y)\n",
    "GRB = pd.DataFrame(score_sf_grb['test_f1'],columns = [\"GRB\"])\n",
    "print(GRB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "364b85b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='tanh', hidden_layer_sizes=(160, 160), max_iter=10000,\n",
      "              random_state=1) \n",
      "\n",
      "score_sf_re: \n",
      "        fit_time  score_time   test_f1  test_precision  test_recall  \\\n",
      "avg  103.017205    0.108929  0.997411        0.997096     0.997727   \n",
      "std   20.311620    0.028797  0.001235        0.001935     0.000932   \n",
      "\n",
      "     test_accuracy  test_roc_auc  \n",
      "avg       0.997521      0.999918  \n",
      "std       0.001184      0.000105  \n",
      "        MLP\n",
      "0  0.999090\n",
      "1  0.996820\n",
      "2  0.995915\n",
      "3  0.999546\n",
      "4  0.995915\n",
      "5  0.998636\n",
      "6  0.997726\n",
      "7  0.997270\n",
      "8  0.996823\n",
      "9  0.996367\n"
     ]
    }
   ],
   "source": [
    "# -------------------- MLP -----------------------\n",
    "score_sf_mlp = train_model(mm, selector, model_mlp, data_aftcat_aftif, data_aftcat_aftif_y)\n",
    "MLP = pd.DataFrame(score_sf_mlp['test_f1'],columns = [\"MLP\"])\n",
    "print(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3845161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=18, max_features=25, random_state=10) \n",
      "\n",
      "score_sf_re: \n",
      "      fit_time  score_time   test_f1  test_precision  test_recall  \\\n",
      "avg  0.472254    0.079859  0.995910        0.995551     0.996273   \n",
      "std  0.046220    0.023368  0.000996        0.001483     0.001598   \n",
      "\n",
      "     test_accuracy  test_roc_auc  \n",
      "avg       0.996086      0.996094  \n",
      "std       0.000953      0.000959  \n",
      "         DT\n",
      "0  0.994998\n",
      "1  0.996370\n",
      "2  0.995007\n",
      "3  0.998182\n",
      "4  0.995007\n",
      "5  0.995455\n",
      "6  0.996817\n",
      "7  0.994989\n",
      "8  0.995915\n",
      "9  0.996367\n"
     ]
    }
   ],
   "source": [
    "# -------------------- DT -----------------------\n",
    "score_sf_dt = train_model(mm, selector, model_dt, data_aftcat_aftif, data_aftcat_aftif_y)\n",
    "DT = pd.DataFrame(score_sf_dt['test_f1'],columns = [\"DT\"])\n",
    "print(DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7ff40e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value of RF and GRB: [0.345183]\n",
      "No significant difference!\n",
      "\n",
      "The p-value of RF and MLP: [0.11076935]\n",
      "No significant difference!\n",
      "\n",
      "The p-value of MLP and GRB: [0.1041164]\n",
      "No significant difference!\n",
      "\n",
      "The p-value of RF and DT: [1.02794833e-05]\n",
      "There is a significant difference between the two algorithms.\n",
      "\n",
      "The p-value of GRB and DT: [1.18676005e-05]\n",
      "There is a significant difference between the two algorithms.\n",
      "\n",
      "The p-value of MLP and DT: [0.00505091]\n",
      "There is a significant difference between the two algorithms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ^^^^ compare the four train models: RF, GRB, MLP, DT using Paired T-test^^^^^^^^^^^^^^^\n",
    "# author:           Kun Yan\n",
    "# student number:   300259303\n",
    "# data:             2021-10-03\n",
    "# Python version:   3.9.7\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# get the t-statistics and p-value of two algorithms based on the ten-fold cross validation\n",
    "# a, b are original cross validation score array\n",
    "\n",
    "def sig_diff(p_a_b):\n",
    "    if p_a_b < 0.05:\n",
    "        print(\"There is a significant difference between the two algorithms.\\n\")\n",
    "    else:\n",
    "        print(\"No significant difference!\\n\")\n",
    "\n",
    "\n",
    "stat_RF_GRB, p_RF_GRB = stats.ttest_rel(np.array(RF),np.array(GRB))\n",
    "print(\"The p-value of RF and GRB:\", p_RF_GRB)\n",
    "sig_diff(p_RF_GRB)\n",
    "\n",
    "stat_RF_MLP, p_RF_MLP = stats.ttest_rel(np.array(RF),np.array(MLP))\n",
    "print(\"The p-value of RF and MLP:\", p_RF_MLP)\n",
    "sig_diff(p_RF_MLP)\n",
    "\n",
    "stat_MLP_GRB, p_MLP_GRB = stats.ttest_rel(np.array(MLP),np.array(GRB))\n",
    "print(\"The p-value of MLP and GRB:\", p_MLP_GRB)\n",
    "sig_diff(p_MLP_GRB)\n",
    "\n",
    "stat_RF_DT, p_RF_DT = stats.ttest_rel(np.array(RF),np.array(DT))\n",
    "print(\"The p-value of RF and DT:\", p_RF_DT)\n",
    "sig_diff(p_RF_DT)\n",
    "\n",
    "stat_GRB_DT, p_GRB_DT = stats.ttest_rel(np.array(GRB),np.array(DT))\n",
    "print(\"The p-value of GRB and DT:\", p_GRB_DT)\n",
    "sig_diff(p_GRB_DT)\n",
    "\n",
    "stat_MLP_DT, p_MLP_DT = stats.ttest_rel(np.array(MLP),np.array(DT))\n",
    "print(\"The p-value of MLP and DT:\", p_MLP_DT)\n",
    "sig_diff(p_MLP_DT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa443afe",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The p-value of RF and GRB: [0.345183]\n",
    "No significant difference!\n",
    "\n",
    "The p-value of RF and MLP: [0.11076935]\n",
    "No significant difference!\n",
    "\n",
    "The p-value of MLP and GRB: [0.1041164]\n",
    "No significant difference!\n",
    "\n",
    "The p-value of RF and DT: [1.02794833e-05]\n",
    "There is a significant difference between the two algorithms.\n",
    "\n",
    "The p-value of GRB and DT: [1.18676005e-05]\n",
    "There is a significant difference between the two algorithms.\n",
    "\n",
    "The p-value of MLP and DT: [0.00505091]\n",
    "There is a significant difference between the two algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
